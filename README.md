# Прогнозирование Индексов Потребительских Цен методами машинного обучения
Проект состоит из нескольких частей:
1) Загрузка/первичная обработка данных.
Скрипт download.py автоматически ищет на сайте РосКомНадзора информацию о месячных индексах потребительских цен и скачивает.
Далее скрипт xltocsv.py преобразует .xlsx в .csv, попутно убирая лишние строки/столбцы.
Оба этих базовых скрипта встроены в веб-приложение.
2) Краткий разведочный анализ данных. С помощью инструментов statsmodels изучаем наши данные, чтобы догадываться, какие модели стоит тренировать. Основные пункты сохранены в analyze.py
3) Обучение и анализ SARIMA моделей.
4) Обучение и анализ Gradient Boosting Decision Trees.
5) Создание веб-приложения (app.py), выводящего график прогнозов моделей на 6 месяцев вперёд. Бонусом идёт 95%-доверительный интервал поверх графика.

## Установка
### Вариант 1. 
Устанавливаем библиотеки из файла requirements.txt с помощью pip.

```bash
pip install scikit-learn==0.24.1
pip install statsmodels==0.13.1
pip install pandas==1.3.5
pip install numpy==1.21.5
pip install flask==2.0.3
pip install openpyxl==3.1.2
pip install matplotlib==3.8.4
pip install Werkzeug==2.2.2
```

### Вариант 2. 
Позволяему Docker'у установить их.

## Приложение
Начать ознакомление предпочтительно с приложения. Реализована возможность мимолётным движением руки получить график прогноза на 6 месяцев вперёд.
На выбор - классическая модель SARIMA и модель градиентного спуска.
Модель GBDT получилась намного точнее в плане MSE, однако у SARIMA более предсказуемое поведение с небольшим доверительным интервалом.
![webapp](https://github.com/FluidGrace/Ru_Consumer_Index_Forecast/assets/168632884/8bce9666-72bb-417b-ab73-eaa14a146691)

## Предварительный анализ данных
С самого начала было решено оставить последние 40 точек данных под тест.
Имеем дело с временным рядом, поэтому первым делом была проверена "наивная" модель y_pred[t]=y[t-1], - в каждый месяц ожидать, что будет как в прошлом. У неё около 1.439 MSE на тесте.
```bash
prediction=data['Index'].shift(1)
```
Изначальный массив данных вёл число от 1991 года. Сразу возник вопрос оставлять ли данные 1990-х. Безусловно, 400 точек обучения, лучше чем 300, но данные того периода с инфляцией по 2600% в год вносили огромный шум в общую картину.
Доверительные интервалы даже ARIMA моделей составляют по 5-10% в каждую сторону, если оставить как есть. Решено отбросить первые 100 месяцев было, когда опытным путём обнаружилось, что модели с вырезанными 90ми имеют ощутимое превосходство в MSE. Даже лучшие модели с 90ми годами имели не менее 1.1 MSE.

Итак, отбросив первые 100 месяцев и запустив 
```bash
plot_acf(train['Index'])
```
Видим периодичность данных невооруженным взглядом.
![acf](https://github.com/FluidGrace/Ru_Consumer_Index_Forecast/assets/168632884/507e3f68-b768-46c3-9381-4c54a9fcaa1a)
